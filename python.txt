Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2015-07-29T11:47:18+08:00

====== python ======
Created 星期三 29 七月 2015

* 使用cookie请求requests.get(url, cookies=cookies)
* 多版本安装：
	http://www.tuicool.com/articles/EnE7nm6
	
* python2.7 -m SimpleHTTPServer 8000
* python3 -m http.server

* sqlalchemy group by order by
	count = func.count('*').label('cnt') 
	query(Tbl.host, count).group_by(Tbl.host).order_by(count.desc()) 
	or 
	query(Tbl.host, func.count('*').label('cnt').group_by(Tbl.host).order_by(desc('cnt')) 
	
* sqlalchemy join: outerjoin = left outer join
	g.session.query(func.count(distinct(BandwidthPlan.user_id)).label('room_count'), UserInfo.room_number)\
				 .outerjoin(UserInfo, UserInfo.user_id == BandwidthPlan.user_id and UserInfo.site_id == BandwidthPlan.site_id)\
				 .filter(UserInfo.site_id == site_id)\
				 .filter(BandwidthPlan.start_time <= date)\
				 .filter(BandwidthPlan.expire_time >= date)\
				 .group_by(UserInfo.room_number)\
				 .all()
	
* sqlalchemy 排序问题：自定义字段与数据库原有字段写法不同
	order_criterion = eval("UserAP.%s.%s()" % (order_field, order_direction)) \
			if order_field not in ('update_cnt', 'user_cnt') else eval("""%s("%s")""" % (order_direction, order_field))
	
* pip install package==2.0.0
* pip install --upgrade pip 更新pip
* gunicorn uwsgi是http server,负责解析http协议然后通过wsgi协议与后端应用通信获得返回值
* sys.setrecursionlimit(1500) 设置递归深度
* 安装pip: http://sharadchhetri.com/2014/05/30/install-pip-centos-rhel-ubuntu-debian/
* 安装mysql-python:
	sudo yum install mysql-devel
	sudo pip install mysql-python

* gunicorn 选项：
	--access-logfile - 表示access log 到控制台
	--log-file=- 表示gunicorn自身的log打到控制台

* pip install -r require.txt 因某个包错误而中断的问题: cat requirements.txt | while read PACKAGE; do pip install "$PACKAGE"; done
* python requests.post: 当指定content-type是application/json时, 需使用data=json.dumps(obj)给出参数
* 字符转ASCII: ord('a')
* python 将具有\u格式的ascii文件转成正常的string: s=f.read().decode('unicode-escape') 相反地，s.encode('unicode-escape')
* 打印具有unicode escape的ascii文件：echo -en "\u的字符串" 或者 print "\u字符串"
* sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)  重新打开stdout, 不使用buffer, 使用输出重定向时可以无延迟
* python3 print函数输出时要指定张编码, 不然其会将字符编码成shell当前的默认编码或者ascii(重定向到文件时), 如果中文被强制编码成ascii, 会报错
	通过PYTHONIOENCODING='utf-8'可以指定python默认编码, 类似于python2的sys.setdefaultencoding('utf-8')
	
* pyenv是用来管理多个版本python的，virtualenv是管理不同的python环境。现在版本的pyenv有pyenv-virtualenv插件，可以不用virtualenv
* os.urandom(24) 可以产生真正的随机串
* flask: EXPLAIN_TEMPLATE_LOADING 可以让flask显示render template的过程
* ipython hot reload:
	%load_ext autoreload
	%autoreload 2

* twisted, greenlet, eventlet, gevent, tornado, coroutine
	twisted: is an event-driven networking engine written in python
	greenlet: 底层，被eventlet和gevent使用
	gevent: systems like gevent use lightweight threads to offer performance comparable to asynchronous systems, but they do not actually make things asynchronous
			cooperative lightweight threads as seen in frameworks like gevent are sometimes called coroutines as well, but in Tornado all coroutines use explicit context switches and are called as asynchronous functions
	tornado：有个万能的coroutine runner
	
	cooperative lightweight threads as seen in frameworks like gevent are sometimes called coroutines as well, but in Tornado all coroutines use explicit context switches and are called as asynchronous functions

* 开FTP: sudo python -m pyftpdlib -w -u sfg -P sfg -p 21
* unicode_escape: s='人'  s.encode("unicode_escape")
* ipython: %history -f filename 可存储已打下的命令
* pytest显示print: pytest -s
* pymysql打印实际执行的sql: print(self.cursor._last_executed)
* 100的二进制python串：b'\x00\x00\x00d', \x00是ascii码是0的空符, \x是16进制
* tor代理可使用multitor: multitor --init 10 --user root --socks-port 9000 --control-port 9900 --proxy privoxy --haproxy
  测试：all_proxy=127.0.0.1:16379 curl http://ipinfo.io/ip
  - 16379 是hadproxy代理统一端口
  - multitor的原理是使用tor建sock5隧道，然后用privoxy将http请求转到sock5，再在privoxy上搭hadproxy统一入口
  - multitor -k 可停止程序

* python多线程研究心得：
    - 本来是要用多线程给hbase test集群打并发
    - 发现线程数已经开到256，并发还是只能到500左右，单个线程就能有200，说明并发并不会随着线程数提高而线性提高
    - 进一步追踪发现，随着线程数的提高，写数据库的语句会从原来的0.005秒变成0.5秒，线程数越大这个值越大，导致并发收敛
    - 经观察，高并发时，cpu使用率依然很低
    - 判断线程并不能利用多核cpu来做相关计算，导致资源竞争，延迟变高，并发打不上去

* 显示某个类所在文件：sys.modules[SSLContext.__module__]
* pyenv python openssl版本与homebrew 不兼容问题：重装pyenv里的python, 带上环境参数：CONFIGURE_OPTS="--with-openssl=$(brew --prefix openssl)" pyenv install 3.6.1
* phoenixdb debug打印的问题：
    from conf.dbsession import new_hbase_session
    import logging
    logging.info('asdkjf')
    logging.root.level = 0
    new_hbase_session.create('TEST', {'ID': '123', 'NAME': 'sfg'})

    分析：
    1. logging.info直接调用，会内置调用logging.basicConfig函数，basicConfig函数会创建一个StreamHandler加到root handlers列表，该handlers打印级别是NOSET，应该是跟随root的打印级别;
        logging.root打印级别保持warning(30);
    2. phoenixdb 直接使用logging.getLogger(__name__)来获取日志对象，其打印级别、handler应该是跟随root
    3. 而scrapy默认会把logging.root的打印级别弄成NOSET(0), 导致phoenixdb的打印对象有打印级别是0的StreamHandler, 同时其打印级别跟随root又正好也是0, 因此phoenixdb打印所有日志
    4. if no logging configuration is provided, then:

    The event is output using a ‘handler of last resort’, stored in logging.lastResort. This internal handler is not associated with any logger, and acts like a StreamHandler which writes the event description message to the current value of sys.stderr (therefore respecting any redirections which may be in effect). No formatting is done on the message - just the bare event description message is printed. The handler’s level is set to WARNING, so all events at this and greater severities will be output.
