* curd的报错：UnexpectedError: must be str, not bytes, 其实是phoenix返回了408(没有在服务端规定的时间内完成请求发送), 是解析这个错误时的报错：
b"<html><body><h1>408 Request Time-out</h1>\nYour browser didn't send a complete request in time.
\n</body></html>\n

* phoenix-sqlline 显示长度设置：!set maxWidth 2048
* 查看hbase table的split points:
    hbase(main):011:0* sfg=get_table 'TAOBAO_COMMENT_SPLIT';
    hbase(main):012:0* sfg.get_splits()
* phoenix-sqlline.py安装：直接下载压缩包解压，里面的bin/*可以直接运行
* phoenixdb cursor放久后execute得到空结果的问题：phoenixdb.cursor.py里execute时，如果参数params是None, 为被当成CreateStatement处理，
  statement_id维持上一个(同一个cursor)，猜测相同的statement_id在后端不是全新的查询，返回空可能与不同statement_id没变有关

* 命令行连接hbase:
    1. 下载phoenix解压进到bin目录执行sqlline.py
    2. 需要各个hbase服务器的主机名解析正确
    3. /etc/hbase/conf/hbase-site.xml里需要加配置项(如果没有该文件及目录，可从phoenix解压后文件中找出并复制到相应位置再修改)：
        ```
        <property>
            <name>phoenix.schema.isNamespaceMappingEnabled</name>
            <value>true</value>
        </property>
        ```

* squirrel(图形客户端)连接hbase:
    1. 下载安装squirrel, 下载phoenix并解压
    2. 由于我们的hbase开启了namespaceMapping，而squirrel无法进行相应配置。
       尝试用`jar uf phoenix-4.14.0-cdh5.14.2-client.jar /etc/hbase/conf/hbase-site.xml`将配置文件压到client jar里也不行
    3. 网上找的方法，需要使用瘦连接的方式，我们的hbase本身也起了瘦服务端: `https://blog.csdn.net/wumiqing1/article/details/85088777`
       - 将瘦客户端jar拷贝到squirrel java/lib目录： phoenix-4.14.0-cdh5.14.2-thin-client.jar
       - 按官方说明`http://phoenix.apache.org/installation.html`配置phoenix driver时
           - URI: `jdbc:phoenix:thin:url=http://10.3.10.233:8765;serialization=PROTOBUF`
           - 类名: `org.apache.phoenix.queryserver.client.Driver`
       - alias链接url同样：`jdbc:phoenix:thin:url=http://10.3.10.233:8765;serialization=PROTOBUF`

* phoenix client.jar 读不到nameMappingEnable配置的问题：
    - HADOOP_CLASSPATH="$(hbase mapredcp):/etc/hbase/conf" hadoop jar /opt/cloudera/parcels/APACHE_PHOENIX/lib/phoenix/phoenix-4.14.0-cdh5.14.2-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool --table TMALL_COMMENT_MR --input /sfg/tmall.comment.-8975801478601287988_-8975491383539225521.csv
    - HADOOP_CLASSPATH="/opt/cloudera/parcels/CDH-5.14.2-1.cdh5.14.2.p0.3/jars/hbase-protocol-1.2.0-cdh5.14.2.jar:/etc/hbase/conf" hadoop jar /opt/cloudera/parcels/APACHE_PHOENIX/lib/phoenix/phoenix-4.14.0-cdh5.14.2-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool --table TMALL_COMMENT_MR --input /sfg/sfg.csv -c ID,COMMENT_TIME,CONTENT,ORIGIN_DATA,PRODUCT_ID,SKU_ID,SNAPSHOT_TIME,USER_LEVEL_ID,USER_NICKNAME
    - 这个环境变量可能也有用：HBASE_CONF_DIR=/etc/hbase/conf/

* 更改表结构后，依然报column notfound的问题，可能与UPDATE_CACHE_FREQUENCY这个参数有关，因为thin query server是一直跑着的，作为代理客户端可能一直没有更新
  貌似的解决办法是：主动连到某台机做个upsert操作
* hbase查看index状态：select TABLE_NAME, cast(INDEX_DISABLE_TIMESTAMP as timestamp) from SYSTEM.CATALOG where index_state is not null limit 10;
* org.apache.phoenix.job.JobManager$1@734e7cc1[Running, pool size = 128, active threads = 128, queued tasks = 5000, completed tasks = 646571046]
  - 调大：phoenix.query.threadPoolSize phoenix.query.queueSize
  - 重启查询客户端：重进phoenix-sqline.py或者重启supervisor里的query_server(每个节点都要)

* Phoenix local index region split死锁问题：https://issues.apache.org/jira/browse/PHOENIX-3838. 貌似需要hbase1.3才可以解决
    So, to sum up: Split's write lock call is waiting on an op to relinquish a read lock, the op is waiting on the indexer to finish, the indexer is waiting to acquire a read lock, which is waiting on Split's write lock. Eventually, the indexer ops timeout completely and the deadlock's broken, but that also triggers the indexer's emergency "kill the region server" behavior, so the region server crashes.

* phoenix重命名：
    第1： 先在hbase上把pho1修改成pho2，具体命令行如下：
        hbase(main):001:0>disable 'pho1'
        hbase(main):001:0>snapshot 'pho1','pho_test'
        hbase(main):001:0>clone_snapshot 'pho_test','pho2'
        hbase(main):001:0>delete_snapshot 'pho_test'
        hbase(main):001:0>drop 'pho1'
    第2：然后再phoenix上修改表pho1成表pho2:
        0: jdbc:phoenix:db1,db2,db3:2181> drop table 'pho1'
        0: jdbc:phoenix:db1,db2,db3:2181>create table 'pho2'("kid" varchar primary key, "info"."name" varchar);

* 测试集群一直提示有region in transition(RIT):
    - fsck: sudo -u hbase hbase hbck -fix; sudo -u hbase hbase hbck -repair均无效;
    - 找到相关的region server重启

* master启动时，一直启动不起来：Timedout 300000ms waiting for namespace table to be assigned
    - 问题可能是region在spliting时被强制重启了
    - 解决办法：sudo -u hdfs hdfs dfs -rm -r -f /hbase/WALs/*

* 一个hbase phoenix query_server可能的问题：
    现象：间隔10秒往一个表里写数据，发现几乎每次都会报: RETRY: OperationFailure: ('', None, None, None)
        for i in range(100000):
        v = str(random.randint(1000, 2000000))
        time.sleep(10)
        print(v)
        new_hbase_session.create('TEST', {'ID': v, 'NAME': v, 'TEXT': v})
    分析：报错在phoenixdb.avatica 129行, 错误信息: phoenix org.apache.calcite.avatica.NoSuchConnectionException,
        即连接已经丢失。而如果写入时间间隔很短，则不会报这个错。这表明放置不用的这10秒，某些connection连接失效了
        致于是程序到query_server的http连接，还是query_server到phoenix的连接，需要进一步定位问题
        连接失效的原因多半是因为query_server负载太高，早期刚使用时并没有类似问题，query_server有一些参数可以尝试进行调节

